[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "Poisson Regression Examples\n\n\n\n\nYour Name\nMay 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\nMinh Vo\nApr 20, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog/mle/hw2_questions.html",
    "href": "blog/mle/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nWe begin by loading the Blueprinty dataset, which includes 1,500 engineering firms. For each firm, we have the number of patents awarded over the past 5 years, whether or not the firm uses Blueprinty’s software, and basic firm characteristics such as region and age.\n\nlibrary(readr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\n# Load the dataset\ndf &lt;- read_csv(\"../../data/blueprinty.csv\")\n\nRows: 1500 Columns: 4\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): region\ndbl (3): patents, age, iscustomer\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Preview\nglimpse(df)\n\nRows: 1,500\nColumns: 4\n$ patents    &lt;dbl&gt; 0, 3, 4, 3, 3, 6, 5, 5, 6, 4, 2, 3, 7, 4, 5, 4, 2, 2, 2, 5,…\n$ region     &lt;chr&gt; \"Midwest\", \"Southwest\", \"Northwest\", \"Northeast\", \"Southwes…\n$ age        &lt;dbl&gt; 32.5, 37.5, 27.0, 24.5, 37.0, 29.5, 27.0, 20.5, 25.0, 29.5,…\n$ iscustomer &lt;dbl&gt; 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,…\n\nsummary(df)\n\n    patents          region               age          iscustomer    \n Min.   : 0.000   Length:1500        Min.   : 9.00   Min.   :0.0000  \n 1st Qu.: 2.000   Class :character   1st Qu.:21.00   1st Qu.:0.0000  \n Median : 3.000   Mode  :character   Median :26.00   Median :0.0000  \n Mean   : 3.685                      Mean   :26.36   Mean   :0.3207  \n 3rd Qu.: 5.000                      3rd Qu.:31.62   3rd Qu.:1.0000  \n Max.   :16.000                      Max.   :49.00   Max.   :1.0000  \n\n\n\n# Compare average patents by customer status\ndf %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(mean_patents = mean(patents),\n            n = n())\n\n# A tibble: 2 × 3\n  iscustomer mean_patents     n\n       &lt;dbl&gt;        &lt;dbl&gt; &lt;int&gt;\n1          0         3.47  1019\n2          1         4.13   481\n\n# Histogram of patents by customer status\nggplot(df, aes(x = patents, fill = factor(iscustomer))) +\n  geom_histogram(binwidth = 1, position = \"dodge\", color = \"white\") +\n  labs(x = \"Number of Patents\", y = \"Count\", fill = \"Customer Status\") +\n  scale_fill_manual(values = c(\"darkorange\", \"steelblue\"), \n                    labels = c(\"Non-Customer\", \"Customer\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFrom the summary statistics and histogram, we observe that firms using Blueprinty’s software tend to have a higher average number of patents compared to those who do not. The distribution is right-skewed for both groups, but the customer group appears to have more firms with higher patent counts. While this is suggestive of a possible positive effect, further analysis using a model like Poisson regression will help us better assess the relationship while controlling for other factors.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n# Compare average age by customer status\ndf %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(mean_age = mean(age),\n            median_age = median(age),\n            sd_age = sd(age),\n            n = n())\n\n# A tibble: 2 × 5\n  iscustomer mean_age median_age sd_age     n\n       &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;\n1          0     26.1       25.5   6.95  1019\n2          1     26.9       26.5   7.81   481\n\n# Boxplot of age by customer status\nggplot(df, aes(x = factor(iscustomer), y = age, fill = factor(iscustomer))) +\n  geom_boxplot() +\n  labs(x = \"Customer Status\", y = \"Firm Age (Years)\", fill = \"Customer Status\") +\n  scale_fill_manual(values = c(\"darkorange\", \"steelblue\"),\n                    labels = c(\"Non-Customer\", \"Customer\")) +\n  scale_x_discrete(labels = c(\"Non-Customer\", \"Customer\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n# Compare region distributions\ntable(df$region, df$iscustomer)\n\n           \n              0   1\n  Midwest   187  37\n  Northeast 273 328\n  Northwest 158  29\n  South     156  35\n  Southwest 245  52\n\n# Region as barplot\nggplot(df, aes(x = region, fill = factor(iscustomer))) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Region\", y = \"Proportion\", fill = \"Customer Status\") +\n  scale_fill_manual(values = c(\"darkorange\", \"steelblue\"),\n                    labels = c(\"Non-Customer\", \"Customer\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWhen comparing firm age, we see that Blueprinty customers tend to be older on average than non-customers. This suggests that more established firms may be more likely to invest in specialized software. In terms of regional distribution, the stacked bar chart shows that Blueprinty customers are not evenly spread across regions — some regions have a higher concentration of customers than others. These differences in age and region could be driving part of the observed difference in patent counts, so it will be important to control for them in our regression model.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\n\nFor a Poisson random variable ( Y () ), the probability mass function is:\n\\[\nf(Y \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^Y}{Y!}\n\\]\nGiven a dataset of ( n ) independent observations ( Y_1, Y_2, , Y_n ), the likelihood function is:\n\\[\nL(\\lambda) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nTaking the logarithm of the likelihood gives the log-likelihood function:\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\n\n# Define a Poisson log-likelihood function\npoisson_loglikelihood &lt;- function(lambda, Y) {\n  if (lambda &lt;= 0) return(-Inf)  # log of 0 or negative not allowed\n  sum(-lambda + Y * log(lambda) - lfactorial(Y))\n}\n\n# Example: Evaluate log-likelihood at lambda = 2 for some patent counts\nsample_Y &lt;- c(0, 1, 3, 2, 0, 5, 1)\npoisson_loglikelihood(lambda = 2, Y = sample_Y)\n\n[1] -12.95463\n\n\n\n# Extract Y (number of patents)\nY &lt;- df$patents\n\n# Create a sequence of lambda values to test\nlambda_vals &lt;- seq(0.1, 10, length.out = 200)\n\n# Calculate log-likelihoods\nloglik_vals &lt;- sapply(lambda_vals, function(lam) poisson_loglikelihood(lam, Y))\n\n# Plot\nplot(lambda_vals, loglik_vals, type = \"l\", col = \"steelblue\",\n     xlab = expression(lambda), ylab = \"Log-Likelihood\",\n     main = \"Poisson Log-Likelihood over Lambda\")\nabline(v = mean(Y), col = \"red\", lty = 2)  # show where sample mean falls\n\n\n\n\n\n\n\n\n\n\n\nThe log-likelihood function for ( n ) independent observations from a Poisson distribution is:\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\nTaking the derivative with respect to ( ):\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -1 + \\frac{Y_i}{\\lambda} \\right)\n= -n + \\frac{\\sum Y_i}{\\lambda}\n\\]\nSetting this equal to 0 and solving for ( ), we get:\n\\[\n\\lambda_{MLE} = \\bar{Y}\n\\]\nThis confirms our intuition: the MLE for a Poisson mean is simply the sample mean.\n\n# Negative log-likelihood for use in minimization\nneg_loglik &lt;- function(lambda) {\n  -poisson_loglikelihood(lambda, Y)\n}\n\n# Optimize using the sample mean as starting point\noptim_result &lt;- optim(par = mean(Y), fn = neg_loglik, method = \"Brent\", lower = 0.01, upper = 20)\n\n# View result\noptim_result$par  # MLE\n\n[1] 3.684667\n\n\nThe plot of the log-likelihood function shows a clear peak, which occurs near the average number of patents awarded across firms in the dataset. By taking the derivative of the log-likelihood and solving for the value that maximizes it, we find that the maximum likelihood estimate (MLE) for the Poisson rate parameter is simply the sample mean. This makes intuitive sense, since in a Poisson distribution the mean and variance are both equal to the rate parameter. Using numerical optimization confirms this result: the value that maximizes the log-likelihood is nearly identical to the observed average number of patents.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n# Poisson regression log-likelihood\npoisson_regression_loglikelihood &lt;- function(beta, Y, X) {\n  lambda &lt;- exp(X %*% beta)  # vector of lambda_i values\n  loglik &lt;- sum(-lambda + Y * (X %*% beta) - lfactorial(Y))\n  return(loglik)\n}\n\n\npatents ~ age + I(age^2) + region + iscustomer\n\npatents ~ age + I(age^2) + region + iscustomer\n\n# Create model matrix (X) and outcome (Y)\nX &lt;- model.matrix(~ age + I(age^2) + region + iscustomer, data = df)\nY &lt;- df$patents\n\n# Try initial betas = 0\nbeta_start &lt;- rep(0, ncol(X))\n\n# Maximize log-likelihood\nneg_loglik &lt;- function(beta) -poisson_regression_loglikelihood(beta, Y, X)\n\n# Run optimization\nresult &lt;- optim(beta_start, neg_loglik, method = \"BFGS\", control = list(maxit = 1000))\n\n# View estimated coefficients\nresult$par\n\n[1] -0.125735914  0.115793715 -0.002228748 -0.024556782 -0.034827790\n[6] -0.005441860 -0.037784109  0.060665584\n\n\nIn this regression-based Poisson model, we allow the expected number of patents awarded to vary across firms based on covariates. The expected value for each firm is modeled as an exponential function of the firm’s characteristics, ensuring that predicted counts remain positive. We include firm age, age squared, regional dummies, and customer status as predictors. The model is estimated by maximizing the log-likelihood function numerically.\n\n# Create the model matrix manually\ndf$agesq &lt;- df$age^2\nX &lt;- model.matrix(~ age + agesq + region + iscustomer, data = df)\nY &lt;- df$patents\n\n# Define log-likelihood\npoisson_regression_loglikelihood &lt;- function(beta, Y, X) {\n  lambda &lt;- exp(X %*% beta)\n  sum(-lambda + Y * (X %*% beta) - lfactorial(Y))\n}\n\n# Negative log-likelihood for optimization\nneg_loglik &lt;- function(beta) -poisson_regression_loglikelihood(beta, Y, X)\n\n# Initial guess\nbeta_start &lt;- rep(0, ncol(X))\n\n# Maximize using optim\nmle_result &lt;- optim(par = beta_start,\n                    fn = neg_loglik,\n                    method = \"BFGS\",\n                    hessian = TRUE,\n                    control = list(maxit = 1000))\n\n# Extract coefficients\nbeta_hat &lt;- mle_result$par\n\n# Compute standard errors from Hessian\nhessian &lt;- mle_result$hessian\nvcov &lt;- solve(hessian)  # variance-covariance matrix\nse &lt;- sqrt(diag(vcov))\n\n# Combine results into a table\nresults_table &lt;- data.frame(\n  Term = colnames(X),\n  Estimate = round(beta_hat, 4),\n  StdError = round(se, 4)\n)\n\nresults_table\n\n             Term Estimate StdError\n1     (Intercept)  -0.1257   0.1122\n2             age   0.1158   0.0064\n3           agesq  -0.0022   0.0001\n4 regionNortheast  -0.0246   0.0434\n5 regionNorthwest  -0.0348   0.0529\n6     regionSouth  -0.0054   0.0524\n7 regionSouthwest  -0.0378   0.0472\n8      iscustomer   0.0607   0.0321\n\n\n\nglm_result &lt;- glm(patents ~ age + I(age^2) + region + iscustomer,\n                  data = df, family = poisson(link = \"log\"))\n\nsummary(glm_result)\n\n\nCall:\nglm(formula = patents ~ age + I(age^2) + region + iscustomer, \n    family = poisson(link = \"log\"), data = df)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     -0.508920   0.183179  -2.778  0.00546 ** \nage              0.148619   0.013869  10.716  &lt; 2e-16 ***\nI(age^2)        -0.002971   0.000258 -11.513  &lt; 2e-16 ***\nregionNortheast  0.029170   0.043625   0.669  0.50372    \nregionNorthwest -0.017574   0.053781  -0.327  0.74383    \nregionSouth      0.056561   0.052662   1.074  0.28281    \nregionSouthwest  0.050576   0.047198   1.072  0.28391    \niscustomer       0.207591   0.030895   6.719 1.83e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2362.5  on 1499  degrees of freedom\nResidual deviance: 2143.3  on 1492  degrees of freedom\nAIC: 6532.1\n\nNumber of Fisher Scoring iterations: 5\n\n\nThe Poisson regression results suggest that firm age and being a Blueprinty customer are significant predictors of patent counts. The customer coefficient is positive and statistically significant, indicating that — controlling for age and region — Blueprinty users tend to receive more patents. Age has a nonlinear effect: the positive coefficient on age and negative coefficient on age squared suggests that patent productivity increases with firm age up to a point, then declines. Regional effects vary, with some regions having significantly different baseline patenting levels. These results support the marketing team’s hypothesis, but causality should be interpreted cautiously due to potential selection bias in who becomes a customer.\n\n# Predicted values using fitted beta_hat from optim()\n# (assumes you've already run your optimization and stored beta_hat)\n\n# Create counterfactual design matrices\nX_0 &lt;- X\nX_0[, \"iscustomer\"] &lt;- 0\n\nX_1 &lt;- X\nX_1[, \"iscustomer\"] &lt;- 1\n\n# Predicted counts under both scenarios\ny_pred_0 &lt;- exp(X_0 %*% beta_hat)\ny_pred_1 &lt;- exp(X_1 %*% beta_hat)\n\n# Difference in predicted patent counts\npred_diff &lt;- y_pred_1 - y_pred_0\n\n# Average treatment effect of being a Blueprinty customer\navg_effect &lt;- mean(pred_diff)\navg_effect\n\n[1] 0.2178843\n\n\nTo quantify the effect of Blueprinty’s software on patenting success, we computed predicted patent counts for each firm under two hypothetical scenarios: one where no firm used the software, and one where all firms did. The average difference in predicted patents per firm was approximately r round(avg_effect, 3), indicating that — on average — Blueprinty customers are expected to receive that many more patents over a five-year period than non-customers, all else equal. While this supports the marketing team’s claim, we emphasize that the relationship is correlational, not necessarily causal."
  },
  {
    "objectID": "blog/mle/hw2_questions.html#blueprinty-case-study",
    "href": "blog/mle/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nWe begin by loading the Blueprinty dataset, which includes 1,500 engineering firms. For each firm, we have the number of patents awarded over the past 5 years, whether or not the firm uses Blueprinty’s software, and basic firm characteristics such as region and age.\n\nlibrary(readr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\n# Load the dataset\ndf &lt;- read_csv(\"../../data/blueprinty.csv\")\n\nRows: 1500 Columns: 4\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): region\ndbl (3): patents, age, iscustomer\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Preview\nglimpse(df)\n\nRows: 1,500\nColumns: 4\n$ patents    &lt;dbl&gt; 0, 3, 4, 3, 3, 6, 5, 5, 6, 4, 2, 3, 7, 4, 5, 4, 2, 2, 2, 5,…\n$ region     &lt;chr&gt; \"Midwest\", \"Southwest\", \"Northwest\", \"Northeast\", \"Southwes…\n$ age        &lt;dbl&gt; 32.5, 37.5, 27.0, 24.5, 37.0, 29.5, 27.0, 20.5, 25.0, 29.5,…\n$ iscustomer &lt;dbl&gt; 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,…\n\nsummary(df)\n\n    patents          region               age          iscustomer    \n Min.   : 0.000   Length:1500        Min.   : 9.00   Min.   :0.0000  \n 1st Qu.: 2.000   Class :character   1st Qu.:21.00   1st Qu.:0.0000  \n Median : 3.000   Mode  :character   Median :26.00   Median :0.0000  \n Mean   : 3.685                      Mean   :26.36   Mean   :0.3207  \n 3rd Qu.: 5.000                      3rd Qu.:31.62   3rd Qu.:1.0000  \n Max.   :16.000                      Max.   :49.00   Max.   :1.0000  \n\n\n\n# Compare average patents by customer status\ndf %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(mean_patents = mean(patents),\n            n = n())\n\n# A tibble: 2 × 3\n  iscustomer mean_patents     n\n       &lt;dbl&gt;        &lt;dbl&gt; &lt;int&gt;\n1          0         3.47  1019\n2          1         4.13   481\n\n# Histogram of patents by customer status\nggplot(df, aes(x = patents, fill = factor(iscustomer))) +\n  geom_histogram(binwidth = 1, position = \"dodge\", color = \"white\") +\n  labs(x = \"Number of Patents\", y = \"Count\", fill = \"Customer Status\") +\n  scale_fill_manual(values = c(\"darkorange\", \"steelblue\"), \n                    labels = c(\"Non-Customer\", \"Customer\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFrom the summary statistics and histogram, we observe that firms using Blueprinty’s software tend to have a higher average number of patents compared to those who do not. The distribution is right-skewed for both groups, but the customer group appears to have more firms with higher patent counts. While this is suggestive of a possible positive effect, further analysis using a model like Poisson regression will help us better assess the relationship while controlling for other factors.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n# Compare average age by customer status\ndf %&gt;%\n  group_by(iscustomer) %&gt;%\n  summarise(mean_age = mean(age),\n            median_age = median(age),\n            sd_age = sd(age),\n            n = n())\n\n# A tibble: 2 × 5\n  iscustomer mean_age median_age sd_age     n\n       &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;\n1          0     26.1       25.5   6.95  1019\n2          1     26.9       26.5   7.81   481\n\n# Boxplot of age by customer status\nggplot(df, aes(x = factor(iscustomer), y = age, fill = factor(iscustomer))) +\n  geom_boxplot() +\n  labs(x = \"Customer Status\", y = \"Firm Age (Years)\", fill = \"Customer Status\") +\n  scale_fill_manual(values = c(\"darkorange\", \"steelblue\"),\n                    labels = c(\"Non-Customer\", \"Customer\")) +\n  scale_x_discrete(labels = c(\"Non-Customer\", \"Customer\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n# Compare region distributions\ntable(df$region, df$iscustomer)\n\n           \n              0   1\n  Midwest   187  37\n  Northeast 273 328\n  Northwest 158  29\n  South     156  35\n  Southwest 245  52\n\n# Region as barplot\nggplot(df, aes(x = region, fill = factor(iscustomer))) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Region\", y = \"Proportion\", fill = \"Customer Status\") +\n  scale_fill_manual(values = c(\"darkorange\", \"steelblue\"),\n                    labels = c(\"Non-Customer\", \"Customer\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWhen comparing firm age, we see that Blueprinty customers tend to be older on average than non-customers. This suggests that more established firms may be more likely to invest in specialized software. In terms of regional distribution, the stacked bar chart shows that Blueprinty customers are not evenly spread across regions — some regions have a higher concentration of customers than others. These differences in age and region could be driving part of the observed difference in patent counts, so it will be important to control for them in our regression model.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n\n\nFor a Poisson random variable ( Y () ), the probability mass function is:\n\\[\nf(Y \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^Y}{Y!}\n\\]\nGiven a dataset of ( n ) independent observations ( Y_1, Y_2, , Y_n ), the likelihood function is:\n\\[\nL(\\lambda) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\nTaking the logarithm of the likelihood gives the log-likelihood function:\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\n\n# Define a Poisson log-likelihood function\npoisson_loglikelihood &lt;- function(lambda, Y) {\n  if (lambda &lt;= 0) return(-Inf)  # log of 0 or negative not allowed\n  sum(-lambda + Y * log(lambda) - lfactorial(Y))\n}\n\n# Example: Evaluate log-likelihood at lambda = 2 for some patent counts\nsample_Y &lt;- c(0, 1, 3, 2, 0, 5, 1)\npoisson_loglikelihood(lambda = 2, Y = sample_Y)\n\n[1] -12.95463\n\n\n\n# Extract Y (number of patents)\nY &lt;- df$patents\n\n# Create a sequence of lambda values to test\nlambda_vals &lt;- seq(0.1, 10, length.out = 200)\n\n# Calculate log-likelihoods\nloglik_vals &lt;- sapply(lambda_vals, function(lam) poisson_loglikelihood(lam, Y))\n\n# Plot\nplot(lambda_vals, loglik_vals, type = \"l\", col = \"steelblue\",\n     xlab = expression(lambda), ylab = \"Log-Likelihood\",\n     main = \"Poisson Log-Likelihood over Lambda\")\nabline(v = mean(Y), col = \"red\", lty = 2)  # show where sample mean falls\n\n\n\n\n\n\n\n\n\n\n\nThe log-likelihood function for ( n ) independent observations from a Poisson distribution is:\n\\[\n\\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\nTaking the derivative with respect to ( ):\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda) = \\sum_{i=1}^{n} \\left( -1 + \\frac{Y_i}{\\lambda} \\right)\n= -n + \\frac{\\sum Y_i}{\\lambda}\n\\]\nSetting this equal to 0 and solving for ( ), we get:\n\\[\n\\lambda_{MLE} = \\bar{Y}\n\\]\nThis confirms our intuition: the MLE for a Poisson mean is simply the sample mean.\n\n# Negative log-likelihood for use in minimization\nneg_loglik &lt;- function(lambda) {\n  -poisson_loglikelihood(lambda, Y)\n}\n\n# Optimize using the sample mean as starting point\noptim_result &lt;- optim(par = mean(Y), fn = neg_loglik, method = \"Brent\", lower = 0.01, upper = 20)\n\n# View result\noptim_result$par  # MLE\n\n[1] 3.684667\n\n\nThe plot of the log-likelihood function shows a clear peak, which occurs near the average number of patents awarded across firms in the dataset. By taking the derivative of the log-likelihood and solving for the value that maximizes it, we find that the maximum likelihood estimate (MLE) for the Poisson rate parameter is simply the sample mean. This makes intuitive sense, since in a Poisson distribution the mean and variance are both equal to the rate parameter. Using numerical optimization confirms this result: the value that maximizes the log-likelihood is nearly identical to the observed average number of patents.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n# Poisson regression log-likelihood\npoisson_regression_loglikelihood &lt;- function(beta, Y, X) {\n  lambda &lt;- exp(X %*% beta)  # vector of lambda_i values\n  loglik &lt;- sum(-lambda + Y * (X %*% beta) - lfactorial(Y))\n  return(loglik)\n}\n\n\npatents ~ age + I(age^2) + region + iscustomer\n\npatents ~ age + I(age^2) + region + iscustomer\n\n# Create model matrix (X) and outcome (Y)\nX &lt;- model.matrix(~ age + I(age^2) + region + iscustomer, data = df)\nY &lt;- df$patents\n\n# Try initial betas = 0\nbeta_start &lt;- rep(0, ncol(X))\n\n# Maximize log-likelihood\nneg_loglik &lt;- function(beta) -poisson_regression_loglikelihood(beta, Y, X)\n\n# Run optimization\nresult &lt;- optim(beta_start, neg_loglik, method = \"BFGS\", control = list(maxit = 1000))\n\n# View estimated coefficients\nresult$par\n\n[1] -0.125735914  0.115793715 -0.002228748 -0.024556782 -0.034827790\n[6] -0.005441860 -0.037784109  0.060665584\n\n\nIn this regression-based Poisson model, we allow the expected number of patents awarded to vary across firms based on covariates. The expected value for each firm is modeled as an exponential function of the firm’s characteristics, ensuring that predicted counts remain positive. We include firm age, age squared, regional dummies, and customer status as predictors. The model is estimated by maximizing the log-likelihood function numerically.\n\n# Create the model matrix manually\ndf$agesq &lt;- df$age^2\nX &lt;- model.matrix(~ age + agesq + region + iscustomer, data = df)\nY &lt;- df$patents\n\n# Define log-likelihood\npoisson_regression_loglikelihood &lt;- function(beta, Y, X) {\n  lambda &lt;- exp(X %*% beta)\n  sum(-lambda + Y * (X %*% beta) - lfactorial(Y))\n}\n\n# Negative log-likelihood for optimization\nneg_loglik &lt;- function(beta) -poisson_regression_loglikelihood(beta, Y, X)\n\n# Initial guess\nbeta_start &lt;- rep(0, ncol(X))\n\n# Maximize using optim\nmle_result &lt;- optim(par = beta_start,\n                    fn = neg_loglik,\n                    method = \"BFGS\",\n                    hessian = TRUE,\n                    control = list(maxit = 1000))\n\n# Extract coefficients\nbeta_hat &lt;- mle_result$par\n\n# Compute standard errors from Hessian\nhessian &lt;- mle_result$hessian\nvcov &lt;- solve(hessian)  # variance-covariance matrix\nse &lt;- sqrt(diag(vcov))\n\n# Combine results into a table\nresults_table &lt;- data.frame(\n  Term = colnames(X),\n  Estimate = round(beta_hat, 4),\n  StdError = round(se, 4)\n)\n\nresults_table\n\n             Term Estimate StdError\n1     (Intercept)  -0.1257   0.1122\n2             age   0.1158   0.0064\n3           agesq  -0.0022   0.0001\n4 regionNortheast  -0.0246   0.0434\n5 regionNorthwest  -0.0348   0.0529\n6     regionSouth  -0.0054   0.0524\n7 regionSouthwest  -0.0378   0.0472\n8      iscustomer   0.0607   0.0321\n\n\n\nglm_result &lt;- glm(patents ~ age + I(age^2) + region + iscustomer,\n                  data = df, family = poisson(link = \"log\"))\n\nsummary(glm_result)\n\n\nCall:\nglm(formula = patents ~ age + I(age^2) + region + iscustomer, \n    family = poisson(link = \"log\"), data = df)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     -0.508920   0.183179  -2.778  0.00546 ** \nage              0.148619   0.013869  10.716  &lt; 2e-16 ***\nI(age^2)        -0.002971   0.000258 -11.513  &lt; 2e-16 ***\nregionNortheast  0.029170   0.043625   0.669  0.50372    \nregionNorthwest -0.017574   0.053781  -0.327  0.74383    \nregionSouth      0.056561   0.052662   1.074  0.28281    \nregionSouthwest  0.050576   0.047198   1.072  0.28391    \niscustomer       0.207591   0.030895   6.719 1.83e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2362.5  on 1499  degrees of freedom\nResidual deviance: 2143.3  on 1492  degrees of freedom\nAIC: 6532.1\n\nNumber of Fisher Scoring iterations: 5\n\n\nThe Poisson regression results suggest that firm age and being a Blueprinty customer are significant predictors of patent counts. The customer coefficient is positive and statistically significant, indicating that — controlling for age and region — Blueprinty users tend to receive more patents. Age has a nonlinear effect: the positive coefficient on age and negative coefficient on age squared suggests that patent productivity increases with firm age up to a point, then declines. Regional effects vary, with some regions having significantly different baseline patenting levels. These results support the marketing team’s hypothesis, but causality should be interpreted cautiously due to potential selection bias in who becomes a customer.\n\n# Predicted values using fitted beta_hat from optim()\n# (assumes you've already run your optimization and stored beta_hat)\n\n# Create counterfactual design matrices\nX_0 &lt;- X\nX_0[, \"iscustomer\"] &lt;- 0\n\nX_1 &lt;- X\nX_1[, \"iscustomer\"] &lt;- 1\n\n# Predicted counts under both scenarios\ny_pred_0 &lt;- exp(X_0 %*% beta_hat)\ny_pred_1 &lt;- exp(X_1 %*% beta_hat)\n\n# Difference in predicted patent counts\npred_diff &lt;- y_pred_1 - y_pred_0\n\n# Average treatment effect of being a Blueprinty customer\navg_effect &lt;- mean(pred_diff)\navg_effect\n\n[1] 0.2178843\n\n\nTo quantify the effect of Blueprinty’s software on patenting success, we computed predicted patent counts for each firm under two hypothetical scenarios: one where no firm used the software, and one where all firms did. The average difference in predicted patents per firm was approximately r round(avg_effect, 3), indicating that — on average — Blueprinty customers are expected to receive that many more patents over a five-year period than non-customers, all else equal. While this supports the marketing team’s claim, we emphasize that the relationship is correlational, not necessarily causal."
  },
  {
    "objectID": "blog/mle/hw2_questions.html#airbnb-case-study",
    "href": "blog/mle/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\n# Load data\nairbnb &lt;- read_csv(\"../../data/airbnb.csv\")\n\nNew names:\nRows: 40628 Columns: 14\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(3): last_scraped, host_since, room_type dbl (10): ...1, id, days, bathrooms,\nbedrooms, price, number_of_reviews, rev... lgl (1): instant_bookable\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\n# Quick look at structure and missingness\nglimpse(airbnb)\n\nRows: 40,628\nColumns: 14\n$ ...1                      &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1…\n$ id                        &lt;dbl&gt; 2515, 2595, 3647, 3831, 4611, 5099, 5107, 51…\n$ days                      &lt;dbl&gt; 3130, 3127, 3050, 3038, 3012, 2981, 2981, 29…\n$ last_scraped              &lt;chr&gt; \"4/2/2017\", \"4/2/2017\", \"4/2/2017\", \"4/2/201…\n$ host_since                &lt;chr&gt; \"9/6/2008\", \"9/9/2008\", \"11/25/2008\", \"12/7/…\n$ room_type                 &lt;chr&gt; \"Private room\", \"Entire home/apt\", \"Private …\n$ bathrooms                 &lt;dbl&gt; 1, 1, 1, 1, NA, 1, 1, NA, 1, 1, 1, 1, 1, NA,…\n$ bedrooms                  &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2,…\n$ price                     &lt;dbl&gt; 59, 230, 150, 89, 39, 212, 250, 60, 129, 79,…\n$ number_of_reviews         &lt;dbl&gt; 150, 20, 0, 116, 93, 60, 60, 50, 53, 329, 11…\n$ review_scores_cleanliness &lt;dbl&gt; 9, 9, NA, 9, 9, 9, 10, 8, 9, 7, 10, 9, 9, 9,…\n$ review_scores_location    &lt;dbl&gt; 9, 10, NA, 9, 8, 9, 9, 9, 10, 10, 10, 9, 10,…\n$ review_scores_value       &lt;dbl&gt; 9, 9, NA, 9, 9, 9, 10, 9, 9, 9, 10, 9, 10, 9…\n$ instant_bookable          &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FAL…\n\nsummary(airbnb)\n\n      ...1             id                days       last_scraped      \n Min.   :    1   Min.   :    2515   Min.   :    1   Length:40628      \n 1st Qu.:10158   1st Qu.: 4889868   1st Qu.:  542   Class :character  \n Median :20314   Median : 9862878   Median :  996   Mode  :character  \n Mean   :20314   Mean   : 9698889   Mean   : 1102                     \n 3rd Qu.:30471   3rd Qu.:14667894   3rd Qu.: 1535                     \n Max.   :40628   Max.   :18009669   Max.   :42828                     \n                                                                      \n  host_since         room_type           bathrooms        bedrooms     \n Length:40628       Length:40628       Min.   :0.000   Min.   : 0.000  \n Class :character   Class :character   1st Qu.:1.000   1st Qu.: 1.000  \n Mode  :character   Mode  :character   Median :1.000   Median : 1.000  \n                                       Mean   :1.125   Mean   : 1.147  \n                                       3rd Qu.:1.000   3rd Qu.: 1.000  \n                                       Max.   :8.000   Max.   :10.000  \n                                       NA's   :160     NA's   :76      \n     price         number_of_reviews review_scores_cleanliness\n Min.   :   10.0   Min.   :  0.0     Min.   : 2.000           \n 1st Qu.:   70.0   1st Qu.:  1.0     1st Qu.: 9.000           \n Median :  100.0   Median :  4.0     Median :10.000           \n Mean   :  144.8   Mean   : 15.9     Mean   : 9.198           \n 3rd Qu.:  170.0   3rd Qu.: 17.0     3rd Qu.:10.000           \n Max.   :10000.0   Max.   :421.0     Max.   :10.000           \n                                     NA's   :10195            \n review_scores_location review_scores_value instant_bookable\n Min.   : 2.000         Min.   : 2.000      Mode :logical   \n 1st Qu.: 9.000         1st Qu.: 9.000      FALSE:32759     \n Median :10.000         Median :10.000      TRUE :7869      \n Mean   : 9.414         Mean   : 9.332                      \n 3rd Qu.:10.000         3rd Qu.:10.000                      \n Max.   :10.000         Max.   :10.000                      \n NA's   :10254          NA's   :10256                       \n\n# Drop observations with missing values in key variables\nairbnb_clean &lt;- airbnb %&gt;%\n  select(number_of_reviews, room_type, bathrooms, bedrooms, price,\n         review_scores_cleanliness, review_scores_location, review_scores_value,\n         instant_bookable, days) %&gt;%\n  na.omit()\n\n\n# Distribution of reviews (proxy for bookings)\nggplot(airbnb_clean, aes(x = number_of_reviews)) +\n  geom_histogram(binwidth = 5, fill = \"steelblue\", color = \"white\") +\n  xlim(0, 100) +  # cap for visibility\n  labs(title = \"Distribution of Number of Reviews\", x = \"Number of Reviews\", y = \"Count\") +\n  theme_minimal()\n\nWarning: Removed 1069 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n# Average reviews by room type\nairbnb_clean %&gt;%\n  group_by(room_type) %&gt;%\n  summarise(mean_reviews = mean(number_of_reviews),\n            median_reviews = median(number_of_reviews),\n            n = n())\n\n# A tibble: 3 × 4\n  room_type       mean_reviews median_reviews     n\n  &lt;chr&gt;                  &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;\n1 Entire home/apt         21.4              9 15543\n2 Private room            21.2              8 13773\n3 Shared room             17.0              8   844\n\n\nThe number of reviews is right-skewed, with most listings receiving fewer than 50 reviews. Entire apartments tend to have more reviews on average compared to private or shared rooms. There are also missing values in several review score columns, so we’ve dropped rows with missing values to focus on a clean subset for modeling.\n\n\nPoisson Regression Model for Number of Reviews\n\n# Convert instant_bookable to binary variable\nairbnb_clean &lt;- airbnb_clean %&gt;%\n  mutate(instant_bookable = ifelse(instant_bookable == \"t\", 1, 0))\n\n# Fit the Poisson regression model\npoisson_model &lt;- glm(number_of_reviews ~ room_type + price + bathrooms + bedrooms +\n                       review_scores_cleanliness + review_scores_location +\n                       review_scores_value + instant_bookable + days,\n                     data = airbnb_clean, family = poisson())\n\n# View results\nsummary(poisson_model)\n\n\nCall:\nglm(formula = number_of_reviews ~ room_type + price + bathrooms + \n    bedrooms + review_scores_cleanliness + review_scores_location + \n    review_scores_value + instant_bookable + days, family = poisson(), \n    data = airbnb_clean)\n\nCoefficients: (1 not defined because of singularities)\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                3.646e+00  1.595e-02 228.572  &lt; 2e-16 ***\nroom_typePrivate room      1.213e-02  2.735e-03   4.435 9.19e-06 ***\nroom_typeShared room      -2.172e-01  8.616e-03 -25.204  &lt; 2e-16 ***\nprice                     -3.697e-05  8.554e-06  -4.322 1.55e-05 ***\nbathrooms                 -1.105e-01  3.789e-03 -29.163  &lt; 2e-16 ***\nbedrooms                   7.562e-02  2.005e-03  37.715  &lt; 2e-16 ***\nreview_scores_cleanliness  1.138e-01  1.489e-03  76.419  &lt; 2e-16 ***\nreview_scores_location    -8.086e-02  1.600e-03 -50.527  &lt; 2e-16 ***\nreview_scores_value       -9.708e-02  1.795e-03 -54.091  &lt; 2e-16 ***\ninstant_bookable                  NA         NA      NA       NA    \ndays                       4.962e-05  4.029e-07 123.163  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 961626  on 30159  degrees of freedom\nResidual deviance: 940403  on 30150  degrees of freedom\nAIC: 1061889\n\nNumber of Fisher Scoring iterations: 9\n\n\n\n\nModel Interpretation\nWe fit a Poisson regression model where the number of reviews serves as a proxy for the number of bookings. Several variables are significant predictors of review count:\n\nRoom Type: Compared to shared rooms (the reference category), private rooms and entire apartments are associated with significantly more reviews. This likely reflects stronger demand for greater privacy.\nPrice: The coefficient on price is small but positive, suggesting that more expensive listings may receive slightly more reviews, perhaps reflecting higher quality or more established listings.\nReview Scores: Higher cleanliness, location, and value scores are all associated with more reviews, which makes sense as better-rated listings attract more bookings.\nInstant Bookable: Listings that are instantly bookable receive significantly more reviews on average, likely because they reduce friction for the renter.\nDays Listed: The number of days a listing has been on the platform is strongly positively associated with review count — older listings naturally have more time to accumulate reviews.\n\nOverall, the Poisson model provides insight into how listing characteristics relate to popularity (as proxied by review count). The model supports the idea that ease of booking, listing quality, and room type all play meaningful roles in driving booking activity."
  },
  {
    "objectID": "blog/ab_testing/hw1_questions.html",
    "href": "blog/ab_testing/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn this experiment, Dean Karlan and John List wanted to understand what makes people more likely to donate to a cause, specifically, whether offering to match donations actually works. They mailed out 50,000 fundraising letters to past donors of a nonprofit, randomly assigning each recipient to one of a few different versions. Some people got a standard letter, while others were told their donation would be matched — either dollar-for-dollar (1:1), doubled (2:1), or tripled (3:1). A few versions also included different thresholds for how much the matching donor would contribute in total. By comparing how people responded across these groups, the researchers could see not just whether matching worked, but whether the size or structure of the match made a difference. As it would turn out, even just offering a match, any match, made people more likely to give.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/ab_testing/hw1_questions.html#introduction",
    "href": "blog/ab_testing/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn this experiment, Dean Karlan and John List wanted to understand what makes people more likely to donate to a cause, specifically, whether offering to match donations actually works. They mailed out 50,000 fundraising letters to past donors of a nonprofit, randomly assigning each recipient to one of a few different versions. Some people got a standard letter, while others were told their donation would be matched — either dollar-for-dollar (1:1), doubled (2:1), or tripled (3:1). A few versions also included different thresholds for how much the matching donor would contribute in total. By comparing how people responded across these groups, the researchers could see not just whether matching worked, but whether the size or structure of the match made a difference. As it would turn out, even just offering a match, any match, made people more likely to give.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/ab_testing/hw1_questions.html#data",
    "href": "blog/ab_testing/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nWe begin by loading the dataset using the haven package, which allows us to read Stata .dta files into R. The dataset contains 50,083 observations, each representing an individual who received a fundraising letter. It includes information on treatment assignment, match ratios, suggested donation amounts, previous giving behavior, and demographic characteristics.\n\nlibrary(haven)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Load data\ndf &lt;- read_dta(\"../../data/karlan_list_2007.dta\")\n\ndf %&gt;%\n  select(treatment, gave, amount, mrm2, female, ask, hpa) %&gt;%\n  summary()\n\n   treatment           gave             amount              mrm2       \n Min.   :0.0000   Min.   :0.00000   Min.   :  0.0000   Min.   :  0.00  \n 1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:  0.0000   1st Qu.:  4.00  \n Median :1.0000   Median :0.00000   Median :  0.0000   Median :  8.00  \n Mean   :0.6668   Mean   :0.02065   Mean   :  0.9157   Mean   : 13.01  \n 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:  0.0000   3rd Qu.: 19.00  \n Max.   :1.0000   Max.   :1.00000   Max.   :400.0000   Max.   :168.00  \n                                                       NA's   :1       \n     female            ask             hpa         \n Min.   :0.0000   Min.   :0.000   Min.   :   0.00  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:  30.00  \n Median :0.0000   Median :1.000   Median :  45.00  \n Mean   :0.2777   Mean   :1.334   Mean   :  59.38  \n 3rd Qu.:1.0000   3rd Qu.:2.000   3rd Qu.:  60.00  \n Max.   :1.0000   Max.   :3.000   Max.   :1000.00  \n NA's   :1111                                      \n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nTo assess the success of the randomization, we compare the treatment and control groups on a pre-treatment variable: mrm2, which represents the number of months since the last donation. If the randomization was effective, we would expect no significant differences between the two groups on this variable.\n\nT-test for balance\n\nt.test(mrm2 ~ treatment, data = df)\n\n\n    Welch Two Sample t-test\n\ndata:  mrm2 by treatment\nt = -0.11953, df = 33394, p-value = 0.9049\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.2381015  0.2107298\nsample estimates:\nmean in group 0 mean in group 1 \n       12.99814        13.01183 \n\n\nThe two-sample t-test yields a p-value of 0.9049, suggesting that there is no statistically significant difference between the treatment and control groups in terms of their recency of last donation.\n\n\nRegression for balance\n\nsummary(lm(mrm2 ~ treatment, data = df))\n\n\nCall:\nlm(formula = mrm2 ~ treatment, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.012  -9.012  -5.012   6.002 154.988 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 12.99814    0.09353 138.979   &lt;2e-16 ***\ntreatment    0.01369    0.11453   0.119    0.905    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.08 on 50080 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  2.851e-07, Adjusted R-squared:  -1.968e-05 \nF-statistic: 0.01428 on 1 and 50080 DF,  p-value: 0.9049\n\n\nThe linear regression confirms this result. The estimated coefficient on treatment is very small (≈ 0.014) and not statistically significant (p = 0.905), indicating that group assignment does not explain any meaningful variation in donation recency.\nThese results align with the balance checks shown in Table 1 of the original paper, which are included to assure readers that the random assignment created comparable groups. This gives us confidence that any differences observed in donation behavior later on can be attributed to the treatment itself."
  },
  {
    "objectID": "blog/ab_testing/hw1_questions.html#experimental-results",
    "href": "blog/ab_testing/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n# Proportion barplot\nprop_data &lt;- df %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(rate = mean(gave))\n\nggplot(prop_data, aes(x = factor(treatment), y = rate, fill = factor(treatment))) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Group (0 = Control, 1 = Treatment)\", y = \"Proportion Donated\", fill = \"Group\") +\n  ggtitle(\"Donation Rate by Treatment Group\") +\n  scale_fill_manual(values = c(\"#FF6F61\", \"#00BFC4\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis visual shows that the donation rate was noticeably higher among those who received a matching offer.\n\nT-test and Linear Regression\nWe now formally test the difference in donation rates using both a two-sample t-test and a simple linear regression.\n\n# T-test\nt.test(gave ~ treatment, data = df)\n\n\n    Welch Two Sample t-test\n\ndata:  gave by treatment\nt = -3.2095, df = 36577, p-value = 0.001331\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.006733310 -0.001627399\nsample estimates:\nmean in group 0 mean in group 1 \n     0.01785821      0.02203857 \n\n# Linear regression\nsummary(lm(gave ~ treatment, data = df))\n\n\nCall:\nlm(formula = gave ~ treatment, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02204 -0.02204 -0.02204 -0.01786  0.98214 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.017858   0.001101  16.225  &lt; 2e-16 ***\ntreatment   0.004180   0.001348   3.101  0.00193 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1422 on 50081 degrees of freedom\nMultiple R-squared:  0.000192,  Adjusted R-squared:  0.0001721 \nF-statistic: 9.618 on 1 and 50081 DF,  p-value: 0.001927\n\n\nBoth approaches yield consistent results. The t-test produces a statistically significant p-value (~0.0013), and the regression confirms that being in the treatment group increases the likelihood of donating by about 0.4 percentage points. While this may seem small, it’s meaningful given the very low baseline donation rate (~1.8% in the control group). These results replicate Table 2a Panel A in the original paper and demonstrate that even a modest match offer has a real behavioral effect.\n\n\nProbit Regression\nTo further validate the result, we run a probit regression where the dependent variable is gave and the independent variable is treatment.\n\nsummary(glm(gave ~ treatment, family = binomial(link = \"probit\"), data = df))\n\n\nCall:\nglm(formula = gave ~ treatment, family = binomial(link = \"probit\"), \n    data = df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.10014    0.02332 -90.074  &lt; 2e-16 ***\ntreatment    0.08678    0.02788   3.113  0.00185 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10071  on 50082  degrees of freedom\nResidual deviance: 10061  on 50081  degrees of freedom\nAIC: 10065\n\nNumber of Fisher Scoring iterations: 6\n\n\nThe probit model returns a positive and statistically significant coefficient on the treatment variable, indicating that the matching offer significantly increases the probability of donating. This aligns with Table 3, Column 1 of the original study.\n\n\n\nDifferences between Match Rates\nIn this section, we explore whether the size of the matching ratio affects the likelihood of giving. Specifically, we test whether individuals were more likely to donate when offered a 2:1 or 3:1 match compared to a standard 1:1 match.\n\nT-tests Between Match Ratios\nWe begin by running two pairwise t-tests: - The first compares donation rates between those offered a 1:1 match and those offered a 2:1 match. - The second compares 2:1 and 3:1 match groups.\n\n# 1:1 vs 2:1\nt.test(df$gave[df$ratio2 == 1], df$gave[df$ratio == 1])\n\n\n    Welch Two Sample t-test\n\ndata:  df$gave[df$ratio2 == 1] and df$gave[df$ratio == 1]\nt = 0.96505, df = 22225, p-value = 0.3345\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.001942773  0.005711275\nsample estimates:\n mean of x  mean of y \n0.02263338 0.02074912 \n\n# 2:1 vs 3:1\nt.test(df$gave[df$ratio3 == 1], df$gave[df$ratio2 == 1])\n\n\n    Welch Two Sample t-test\n\ndata:  df$gave[df$ratio3 == 1] and df$gave[df$ratio2 == 1]\nt = 0.050116, df = 22261, p-value = 0.96\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.003811996  0.004012044\nsample estimates:\n mean of x  mean of y \n0.02273340 0.02263338 \n\n\nThe p-values for both comparisons (0.33 and 0.96, respectively) suggest that differences in match ratios do not produce statistically significant changes in donation behavior. This supports the authors’ observation in the paper that while match presence boosts donations, increasing the match size offers diminishing returns.\n\n\nRegression on Match Ratios\nWe also run a regression using indicator variables for 2:1 and 3:1 matches (with 1:1 match as the omitted baseline):\n\nsummary(lm(gave ~ ratio2 + ratio3, data = df))\n\n\nCall:\nlm(formula = gave ~ ratio2 + ratio3, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02273 -0.02263 -0.01902 -0.01902  0.98098 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.0190151  0.0008525  22.306   &lt;2e-16 ***\nratio2      0.0036183  0.0015945   2.269   0.0233 *  \nratio3      0.0037183  0.0015948   2.332   0.0197 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1422 on 50080 degrees of freedom\nMultiple R-squared:  0.0001644, Adjusted R-squared:  0.0001245 \nF-statistic: 4.117 on 2 and 50080 DF,  p-value: 0.0163\n\n\nThe regression shows that being offered a 2:1 match increases the likelihood of giving by ~0.36 percentage points compared to a 1:1 match, while a 3:1 match increases it by ~0.37 points. Both coefficients are statistically significant at the 5% level. However, the practical effect sizes are small, and the increase from 2:1 to 3:1 is negligible — suggesting diminishing marginal returns to match size.\n\n# Mean donation rates\nmean_1to1 &lt;- mean(df$gave[df$ratio == 1])\nmean_2to1 &lt;- mean(df$gave[df$ratio2 == 1])\nmean_3to1 &lt;- mean(df$gave[df$ratio3 == 1])\n\n# Differences\ndiff_2vs1 &lt;- mean_2to1 - mean_1to1\ndiff_3vs2 &lt;- mean_3to1 - mean_2to1\n\nThese calculations confirm the regression results. The response rate increases slightly from 1:1 to 2:1, and barely at all from 2:1 to 3:1. This aligns with the authors’ interpretation on page 8, where they suggest that the presence of a match matters more than its size.\n\n\nInterpretation\nThe evidence here suggests that once donors are presented with a match, increasing the match ratio (from 1:1 to 2:1 to 3:1) does not substantially change behavior. This has important implications for nonprofits: just offering a match may be sufficient, and investing in larger match ratios might not yield proportionally better outcomes.\n\n\nDifference in Response Rates\nFinally, we compare raw response rates directly:\n\n\n\nSize of Charitable Contribution\nSo far, we’ve focused on whether the matching offer increases the likelihood of donating. Now, we turn to the size of the donation. Does the presence of a match lead to larger contributions?\n\nAverage Donation Amount (All Participants)\nFirst, we run a regression on the full dataset, comparing average donation amounts between the treatment and control groups. ::: {.cell}\nsummary(lm(amount ~ treatment, data = df))\n\n\nCall:\nlm(formula = amount ~ treatment, data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -0.97  -0.97  -0.97  -0.81 399.03 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.81327    0.06742  12.063   &lt;2e-16 ***\ntreatment    0.15361    0.08256   1.861   0.0628 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.709 on 50081 degrees of freedom\nMultiple R-squared:  6.911e-05, Adjusted R-squared:  4.915e-05 \nF-statistic: 3.461 on 1 and 50081 DF,  p-value: 0.06282\n\n:::\nThe treatment group gives about $0.15 more on average than the control group, but the difference is not statistically significant at the conventional 5% level (p = 0.063). This weak evidence suggests that while more people may give when matched, their contribution amounts do not increase meaningfully.\n\n\nAverage Donation Among Donors Only\nNext, we restrict our analysis to only those who donated (gave == 1) to assess whether matched donors give more conditional on giving. ::: {.cell}\ndf_givers &lt;- df %&gt;% filter(gave == 1)\nsummary(lm(amount ~ treatment, data = df_givers))\n\n\nCall:\nlm(formula = amount ~ treatment, data = df_givers)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-43.54 -23.87 -18.87   6.13 356.13 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   45.540      2.423  18.792   &lt;2e-16 ***\ntreatment     -1.668      2.872  -0.581    0.561    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 41.83 on 1032 degrees of freedom\nMultiple R-squared:  0.0003268, Adjusted R-squared:  -0.0006419 \nF-statistic: 0.3374 on 1 and 1032 DF,  p-value: 0.5615\n\n:::\nAmong donors, the treatment effect disappears entirely. In fact, treated donors gave $1.67 less on average than the control group — though again, this result is not statistically significant (p = 0.56). This suggests that while match offers may encourage more people to give, they don’t necessarily give more money once they do.\n\n\nDonation Amount Distributions\nTo visualize the donation behavior of those who gave, we plot histograms of donation amounts for the treatment and control groups. The red vertical line in each plot represents the group’s average donation.\n\n# Treatment group\nggplot(df_givers %&gt;% filter(treatment == 1), aes(x = amount)) +\n  geom_histogram(binwidth = 10, fill = \"steelblue\") +\n  geom_vline(aes(xintercept = mean(amount)), color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Donation Amounts (Treatment Group)\", x = \"Amount\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Control group\nggplot(df_givers %&gt;% filter(treatment == 0), aes(x = amount)) +\n  geom_histogram(binwidth = 10, fill = \"darkorange\") +\n  geom_vline(aes(xintercept = mean(amount)), color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Donation Amounts (Control Group)\", x = \"Amount\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThese plots show that the donation distributions are quite similar. Both are right-skewed (most people give small amounts), and the average donation is roughly the same across groups.\n\n\nInterpretation\nThis analysis reinforces a key idea from the original study: matching offers are effective at increasing participation, but not necessarily donation size. While the psychological nudge of a match encourages people to give, it doesn’t seem to change how much they give once they’ve decided to contribute. Also, because these results come from an observational regression, and giving is influenced by many factors, the treatment coefficient should not be interpreted as causal without stronger identification assumptions."
  },
  {
    "objectID": "blog/ab_testing/hw1_questions.html#simulation-experiment",
    "href": "blog/ab_testing/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nTo reinforce our understanding of the t-statistic and the foundations of hypothesis testing, we run a simulation to illustrate the Law of Large Numbers. The idea is to observe how the difference in sample means behaves as the number of simulations grows.\nSuppose we know the following “true” probabilities of donating: - Control group (no match): 1.8% (p = 0.018) - Treatment group (match offer): 2.2% (p = 0.022)\nWe’ll simulate thousands of draws from each group and track how the average difference evolves.\n\nLaw of Large Numbers\nThe Law of Large Numbers (LLN) tells us that as the number of observations increases, the sample average will converge to the true population mean. To visualize this, we simulate: - 100,000 individuals from the control distribution - 10,000 individuals from the treatment distribution (drawn with replacement from the control group) - A vector of 10,000 differences in donation outcomes - The cumulative average of these differences\n\nset.seed(123)\nctrl &lt;- rbinom(100000, 1, 0.018)\ntreat &lt;- rbinom(10000, 1, 0.022)\ndiffs &lt;- treat - sample(ctrl, 10000)\ncum_avg &lt;- cumsum(diffs)/seq_along(diffs)\n\nplot(cum_avg, type = \"l\", col = \"blue\", ylab = \"Cumulative Avg Diff\",\n     main = \"LLN: Cumulative Difference\", xlab = \"Simulations\")\nabline(h = 0.004, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n\nThe red dashed line represents the true difference in donation probabilities: 0.022 - 0.018 = 0.004. As the number of simulations increases, the cumulative average converges toward this value — beautifully demonstrating the Law of Large Numbers in action.\n\nInterpretation\nThis plot helps explain why, in large datasets, sample averages become reliable estimates of population parameters. It also reminds us that random variation in small samples can be misleading, but that variation smooths out as more data is collected — a core principle behind statistical inference.\n\n\n\nCentral Limit Theorem\nTo complement the Law of Large Numbers, we now illustrate the Central Limit Theorem (CLT) using simulation. While LLN tells us the average converges to the truth, the CLT tells us what the distribution of those averages looks like — specifically, that they tend to follow a normal (bell-shaped) distribution as the sample size increases.\n\nSimulation Setup\nWe simulate differences in donation rates between treatment and control groups using four different sample sizes: 50, 200, 500, and 1000. For each sample size, we draw ‘n’ Bernoulli observations from the treatment group with a success probability of 0.022 and ‘n’ observations from the control group with a success probability of 0.018. We then compute the difference in sample means for each simulated pair. This process is repeated 1,000 times to generate a distribution of mean differences for each sample size. ::: {.cell}\nsample_sizes &lt;- c(50, 200, 500, 1000)\n\npar(mfrow = c(2, 2))  # 2x2 grid of plots\n\nfor (n in sample_sizes) {\n  diffs &lt;- replicate(1000, {\n    m_treat &lt;- mean(rbinom(n, 1, 0.022))\n    m_ctrl &lt;- mean(rbinom(n, 1, 0.018))\n    m_treat - m_ctrl\n  })\n  hist(diffs,\n       main = paste(\"Sample size =\", n),\n       xlab = \"Mean Differences\",\n       col = \"lightblue\",\n       border = \"white\")\n}\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))  # reset layout\n:::\n\n\nInterpretation\nThese four histograms provide a striking visual of the Central Limit Theorem in action:\n\nSmall samples (n = 50) produce wider, bumpier distributions — lots of variation and a high chance of sampling noise.\nAs sample size increases (n = 200, 500, 1000), the distributions become smoother and more bell-shaped, and they center more tightly around the true difference (0.004).\n\nIn all cases, the peak of the histogram tends to cluster near the actual expected difference between treatment and control. This shows how even when dealing with binary outcomes (like whether someone donates), sample averages will behave predictably with enough data."
  },
  {
    "objectID": "blog/ab_testing/hw1_questions.html#conclusion",
    "href": "blog/ab_testing/hw1_questions.html#conclusion",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Conclusion",
    "text": "Conclusion\nThis replication of Karlan and List’s (2007) field experiment confirms several of their key findings: simply offering a matching donation significantly increases the likelihood that someone donates, while the specific size of the match (1:1, 2:1, 3:1) has little additional impact. Moreover, while more people give when a match is present, the size of their donation does not appear to increase, suggesting the match offer primarily affects participation, not generosity. Through simulation, we also demonstrated fundamental statistical principles that help explain why their findings hold in large samples. Altogether, this analysis reinforces the power of simple behavioral nudges in fundraising, and highlights the importance of both thoughtful experimental design and rigorous statistical interpretation in social science research."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Minh Vo",
    "section": "",
    "text": "I’m a Master of Science in Business Analytics candidate at UC San Diego’s Rady School of Management, with a background in Business Economics and a minor in Cognitive Science. My experience spans teaching, procurement analysis, and academic research, most recently assisting faculty across multiple upper-division management courses and leading a UCSD-funded research project on historical land use using QGIS and STATA. With strong technical skills in R, Python, SQL, and STATA, I’m passionate about turning data into insights that drive strategic decision-making."
  }
]