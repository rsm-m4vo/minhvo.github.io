[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\nMinh Vo\nApr 20, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog/ab_testing/hw1_questions.html",
    "href": "blog/ab_testing/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn this experiment, Dean Karlan and John List wanted to understand what makes people more likely to donate to a cause, specifically, whether offering to match donations actually works. They mailed out 50,000 fundraising letters to past donors of a nonprofit, randomly assigning each recipient to one of a few different versions. Some people got a standard letter, while others were told their donation would be matched — either dollar-for-dollar (1:1), doubled (2:1), or tripled (3:1). A few versions also included different thresholds for how much the matching donor would contribute in total. By comparing how people responded across these groups, the researchers could see not just whether matching worked, but whether the size or structure of the match made a difference. As it would turn out, even just offering a match, any match, made people more likely to give.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/ab_testing/hw1_questions.html#introduction",
    "href": "blog/ab_testing/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn this experiment, Dean Karlan and John List wanted to understand what makes people more likely to donate to a cause, specifically, whether offering to match donations actually works. They mailed out 50,000 fundraising letters to past donors of a nonprofit, randomly assigning each recipient to one of a few different versions. Some people got a standard letter, while others were told their donation would be matched — either dollar-for-dollar (1:1), doubled (2:1), or tripled (3:1). A few versions also included different thresholds for how much the matching donor would contribute in total. By comparing how people responded across these groups, the researchers could see not just whether matching worked, but whether the size or structure of the match made a difference. As it would turn out, even just offering a match, any match, made people more likely to give.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/ab_testing/hw1_questions.html#data",
    "href": "blog/ab_testing/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nWe begin by loading the dataset using the haven package, which allows us to read Stata .dta files into R. The dataset contains 50,083 observations, each representing an individual who received a fundraising letter. It includes information on treatment assignment, match ratios, suggested donation amounts, previous giving behavior, and demographic characteristics.\n\nlibrary(haven)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\n# Load data\ndf &lt;- read_dta(\"../../data/karlan_list_2007.dta\")\n\ndf %&gt;%\n  select(treatment, gave, amount, mrm2, female, ask, hpa) %&gt;%\n  summary()\n\n   treatment           gave             amount              mrm2       \n Min.   :0.0000   Min.   :0.00000   Min.   :  0.0000   Min.   :  0.00  \n 1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:  0.0000   1st Qu.:  4.00  \n Median :1.0000   Median :0.00000   Median :  0.0000   Median :  8.00  \n Mean   :0.6668   Mean   :0.02065   Mean   :  0.9157   Mean   : 13.01  \n 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:  0.0000   3rd Qu.: 19.00  \n Max.   :1.0000   Max.   :1.00000   Max.   :400.0000   Max.   :168.00  \n                                                       NA's   :1       \n     female            ask             hpa         \n Min.   :0.0000   Min.   :0.000   Min.   :   0.00  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:  30.00  \n Median :0.0000   Median :1.000   Median :  45.00  \n Mean   :0.2777   Mean   :1.334   Mean   :  59.38  \n 3rd Qu.:1.0000   3rd Qu.:2.000   3rd Qu.:  60.00  \n Max.   :1.0000   Max.   :3.000   Max.   :1000.00  \n NA's   :1111                                      \n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nTo assess the success of the randomization, we compare the treatment and control groups on a pre-treatment variable: mrm2, which represents the number of months since the last donation. If the randomization was effective, we would expect no significant differences between the two groups on this variable.\n\nT-test for balance\n\nt.test(mrm2 ~ treatment, data = df)\n\n\n    Welch Two Sample t-test\n\ndata:  mrm2 by treatment\nt = -0.11953, df = 33394, p-value = 0.9049\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.2381015  0.2107298\nsample estimates:\nmean in group 0 mean in group 1 \n       12.99814        13.01183 \n\n\nThe two-sample t-test yields a p-value of 0.9049, suggesting that there is no statistically significant difference between the treatment and control groups in terms of their recency of last donation.\n\n\nRegression for balance\n\nsummary(lm(mrm2 ~ treatment, data = df))\n\n\nCall:\nlm(formula = mrm2 ~ treatment, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-13.012  -9.012  -5.012   6.002 154.988 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 12.99814    0.09353 138.979   &lt;2e-16 ***\ntreatment    0.01369    0.11453   0.119    0.905    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.08 on 50080 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  2.851e-07, Adjusted R-squared:  -1.968e-05 \nF-statistic: 0.01428 on 1 and 50080 DF,  p-value: 0.9049\n\n\nThe linear regression confirms this result. The estimated coefficient on treatment is very small (≈ 0.014) and not statistically significant (p = 0.905), indicating that group assignment does not explain any meaningful variation in donation recency.\nThese results align with the balance checks shown in Table 1 of the original paper, which are included to assure readers that the random assignment created comparable groups. This gives us confidence that any differences observed in donation behavior later on can be attributed to the treatment itself."
  },
  {
    "objectID": "blog/ab_testing/hw1_questions.html#experimental-results",
    "href": "blog/ab_testing/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n# Proportion barplot\nprop_data &lt;- df %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(rate = mean(gave))\n\nggplot(prop_data, aes(x = factor(treatment), y = rate, fill = factor(treatment))) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Group (0 = Control, 1 = Treatment)\", y = \"Proportion Donated\", fill = \"Group\") +\n  ggtitle(\"Donation Rate by Treatment Group\") +\n  scale_fill_manual(values = c(\"#FF6F61\", \"#00BFC4\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis visual shows that the donation rate was noticeably higher among those who received a matching offer.\n\nT-test and Linear Regression\nWe now formally test the difference in donation rates using both a two-sample t-test and a simple linear regression.\n\n# T-test\nt.test(gave ~ treatment, data = df)\n\n\n    Welch Two Sample t-test\n\ndata:  gave by treatment\nt = -3.2095, df = 36577, p-value = 0.001331\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.006733310 -0.001627399\nsample estimates:\nmean in group 0 mean in group 1 \n     0.01785821      0.02203857 \n\n# Linear regression\nsummary(lm(gave ~ treatment, data = df))\n\n\nCall:\nlm(formula = gave ~ treatment, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02204 -0.02204 -0.02204 -0.01786  0.98214 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.017858   0.001101  16.225  &lt; 2e-16 ***\ntreatment   0.004180   0.001348   3.101  0.00193 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1422 on 50081 degrees of freedom\nMultiple R-squared:  0.000192,  Adjusted R-squared:  0.0001721 \nF-statistic: 9.618 on 1 and 50081 DF,  p-value: 0.001927\n\n\nBoth approaches yield consistent results. The t-test produces a statistically significant p-value (~0.0013), and the regression confirms that being in the treatment group increases the likelihood of donating by about 0.4 percentage points. While this may seem small, it’s meaningful given the very low baseline donation rate (~1.8% in the control group). These results replicate Table 2a Panel A in the original paper and demonstrate that even a modest match offer has a real behavioral effect.\n\n\nProbit Regression\nTo further validate the result, we run a probit regression where the dependent variable is gave and the independent variable is treatment.\n\nsummary(glm(gave ~ treatment, family = binomial(link = \"probit\"), data = df))\n\n\nCall:\nglm(formula = gave ~ treatment, family = binomial(link = \"probit\"), \n    data = df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.10014    0.02332 -90.074  &lt; 2e-16 ***\ntreatment    0.08678    0.02788   3.113  0.00185 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10071  on 50082  degrees of freedom\nResidual deviance: 10061  on 50081  degrees of freedom\nAIC: 10065\n\nNumber of Fisher Scoring iterations: 6\n\n\nThe probit model returns a positive and statistically significant coefficient on the treatment variable, indicating that the matching offer significantly increases the probability of donating. This aligns with Table 3, Column 1 of the original study.\n\n\n\nDifferences between Match Rates\nIn this section, we explore whether the size of the matching ratio affects the likelihood of giving. Specifically, we test whether individuals were more likely to donate when offered a 2:1 or 3:1 match compared to a standard 1:1 match.\n\nT-tests Between Match Ratios\nWe begin by running two pairwise t-tests: - The first compares donation rates between those offered a 1:1 match and those offered a 2:1 match. - The second compares 2:1 and 3:1 match groups.\n\n# 1:1 vs 2:1\nt.test(df$gave[df$ratio2 == 1], df$gave[df$ratio == 1])\n\n\n    Welch Two Sample t-test\n\ndata:  df$gave[df$ratio2 == 1] and df$gave[df$ratio == 1]\nt = 0.96505, df = 22225, p-value = 0.3345\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.001942773  0.005711275\nsample estimates:\n mean of x  mean of y \n0.02263338 0.02074912 \n\n# 2:1 vs 3:1\nt.test(df$gave[df$ratio3 == 1], df$gave[df$ratio2 == 1])\n\n\n    Welch Two Sample t-test\n\ndata:  df$gave[df$ratio3 == 1] and df$gave[df$ratio2 == 1]\nt = 0.050116, df = 22261, p-value = 0.96\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.003811996  0.004012044\nsample estimates:\n mean of x  mean of y \n0.02273340 0.02263338 \n\n\nThe p-values for both comparisons (0.33 and 0.96, respectively) suggest that differences in match ratios do not produce statistically significant changes in donation behavior. This supports the authors’ observation in the paper that while match presence boosts donations, increasing the match size offers diminishing returns.\n\n\nRegression on Match Ratios\nWe also run a regression using indicator variables for 2:1 and 3:1 matches (with 1:1 match as the omitted baseline):\n\nsummary(lm(gave ~ ratio2 + ratio3, data = df))\n\n\nCall:\nlm(formula = gave ~ ratio2 + ratio3, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02273 -0.02263 -0.01902 -0.01902  0.98098 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.0190151  0.0008525  22.306   &lt;2e-16 ***\nratio2      0.0036183  0.0015945   2.269   0.0233 *  \nratio3      0.0037183  0.0015948   2.332   0.0197 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1422 on 50080 degrees of freedom\nMultiple R-squared:  0.0001644, Adjusted R-squared:  0.0001245 \nF-statistic: 4.117 on 2 and 50080 DF,  p-value: 0.0163\n\n\nThe regression shows that being offered a 2:1 match increases the likelihood of giving by ~0.36 percentage points compared to a 1:1 match, while a 3:1 match increases it by ~0.37 points. Both coefficients are statistically significant at the 5% level. However, the practical effect sizes are small, and the increase from 2:1 to 3:1 is negligible — suggesting diminishing marginal returns to match size.\n\n# Mean donation rates\nmean_1to1 &lt;- mean(df$gave[df$ratio == 1])\nmean_2to1 &lt;- mean(df$gave[df$ratio2 == 1])\nmean_3to1 &lt;- mean(df$gave[df$ratio3 == 1])\n\n# Differences\ndiff_2vs1 &lt;- mean_2to1 - mean_1to1\ndiff_3vs2 &lt;- mean_3to1 - mean_2to1\n\nThese calculations confirm the regression results. The response rate increases slightly from 1:1 to 2:1, and barely at all from 2:1 to 3:1. This aligns with the authors’ interpretation on page 8, where they suggest that the presence of a match matters more than its size.\n\n\nInterpretation\nThe evidence here suggests that once donors are presented with a match, increasing the match ratio (from 1:1 to 2:1 to 3:1) does not substantially change behavior. This has important implications for nonprofits: just offering a match may be sufficient, and investing in larger match ratios might not yield proportionally better outcomes.\n\n\nDifference in Response Rates\nFinally, we compare raw response rates directly:\n\n\n\nSize of Charitable Contribution\nSo far, we’ve focused on whether the matching offer increases the likelihood of donating. Now, we turn to the size of the donation. Does the presence of a match lead to larger contributions?\n\nAverage Donation Amount (All Participants)\nFirst, we run a regression on the full dataset, comparing average donation amounts between the treatment and control groups. ::: {.cell}\nsummary(lm(amount ~ treatment, data = df))\n\n\nCall:\nlm(formula = amount ~ treatment, data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -0.97  -0.97  -0.97  -0.81 399.03 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.81327    0.06742  12.063   &lt;2e-16 ***\ntreatment    0.15361    0.08256   1.861   0.0628 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.709 on 50081 degrees of freedom\nMultiple R-squared:  6.911e-05, Adjusted R-squared:  4.915e-05 \nF-statistic: 3.461 on 1 and 50081 DF,  p-value: 0.06282\n\n:::\nThe treatment group gives about $0.15 more on average than the control group, but the difference is not statistically significant at the conventional 5% level (p = 0.063). This weak evidence suggests that while more people may give when matched, their contribution amounts do not increase meaningfully.\n\n\nAverage Donation Among Donors Only\nNext, we restrict our analysis to only those who donated (gave == 1) to assess whether matched donors give more conditional on giving. ::: {.cell}\ndf_givers &lt;- df %&gt;% filter(gave == 1)\nsummary(lm(amount ~ treatment, data = df_givers))\n\n\nCall:\nlm(formula = amount ~ treatment, data = df_givers)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-43.54 -23.87 -18.87   6.13 356.13 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   45.540      2.423  18.792   &lt;2e-16 ***\ntreatment     -1.668      2.872  -0.581    0.561    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 41.83 on 1032 degrees of freedom\nMultiple R-squared:  0.0003268, Adjusted R-squared:  -0.0006419 \nF-statistic: 0.3374 on 1 and 1032 DF,  p-value: 0.5615\n\n:::\nAmong donors, the treatment effect disappears entirely. In fact, treated donors gave $1.67 less on average than the control group — though again, this result is not statistically significant (p = 0.56). This suggests that while match offers may encourage more people to give, they don’t necessarily give more money once they do.\n\n\nDonation Amount Distributions\nTo visualize the donation behavior of those who gave, we plot histograms of donation amounts for the treatment and control groups. The red vertical line in each plot represents the group’s average donation.\n\n# Treatment group\nggplot(df_givers %&gt;% filter(treatment == 1), aes(x = amount)) +\n  geom_histogram(binwidth = 10, fill = \"steelblue\") +\n  geom_vline(aes(xintercept = mean(amount)), color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Donation Amounts (Treatment Group)\", x = \"Amount\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Control group\nggplot(df_givers %&gt;% filter(treatment == 0), aes(x = amount)) +\n  geom_histogram(binwidth = 10, fill = \"darkorange\") +\n  geom_vline(aes(xintercept = mean(amount)), color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Donation Amounts (Control Group)\", x = \"Amount\", y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThese plots show that the donation distributions are quite similar. Both are right-skewed (most people give small amounts), and the average donation is roughly the same across groups.\n\n\nInterpretation\nThis analysis reinforces a key idea from the original study: matching offers are effective at increasing participation, but not necessarily donation size. While the psychological nudge of a match encourages people to give, it doesn’t seem to change how much they give once they’ve decided to contribute. Also, because these results come from an observational regression, and giving is influenced by many factors, the treatment coefficient should not be interpreted as causal without stronger identification assumptions."
  },
  {
    "objectID": "blog/ab_testing/hw1_questions.html#simulation-experiment",
    "href": "blog/ab_testing/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nTo reinforce our understanding of the t-statistic and the foundations of hypothesis testing, we run a simulation to illustrate the Law of Large Numbers. The idea is to observe how the difference in sample means behaves as the number of simulations grows.\nSuppose we know the following “true” probabilities of donating: - Control group (no match): 1.8% (p = 0.018) - Treatment group (match offer): 2.2% (p = 0.022)\nWe’ll simulate thousands of draws from each group and track how the average difference evolves.\n\nLaw of Large Numbers\nThe Law of Large Numbers (LLN) tells us that as the number of observations increases, the sample average will converge to the true population mean. To visualize this, we simulate: - 100,000 individuals from the control distribution - 10,000 individuals from the treatment distribution (drawn with replacement from the control group) - A vector of 10,000 differences in donation outcomes - The cumulative average of these differences\n\nset.seed(123)\nctrl &lt;- rbinom(100000, 1, 0.018)\ntreat &lt;- rbinom(10000, 1, 0.022)\ndiffs &lt;- treat - sample(ctrl, 10000)\ncum_avg &lt;- cumsum(diffs)/seq_along(diffs)\n\nplot(cum_avg, type = \"l\", col = \"blue\", ylab = \"Cumulative Avg Diff\",\n     main = \"LLN: Cumulative Difference\", xlab = \"Simulations\")\nabline(h = 0.004, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n\nThe red dashed line represents the true difference in donation probabilities: 0.022 - 0.018 = 0.004. As the number of simulations increases, the cumulative average converges toward this value — beautifully demonstrating the Law of Large Numbers in action.\n\nInterpretation\nThis plot helps explain why, in large datasets, sample averages become reliable estimates of population parameters. It also reminds us that random variation in small samples can be misleading, but that variation smooths out as more data is collected — a core principle behind statistical inference.\n\n\n\nCentral Limit Theorem\nTo complement the Law of Large Numbers, we now illustrate the Central Limit Theorem (CLT) using simulation. While LLN tells us the average converges to the truth, the CLT tells us what the distribution of those averages looks like — specifically, that they tend to follow a normal (bell-shaped) distribution as the sample size increases.\n\nSimulation Setup\nWe simulate differences in donation rates between treatment and control groups using four different sample sizes: 50, 200, 500, and 1000. For each sample size, we draw ‘n’ Bernoulli observations from the treatment group with a success probability of 0.022 and ‘n’ observations from the control group with a success probability of 0.018. We then compute the difference in sample means for each simulated pair. This process is repeated 1,000 times to generate a distribution of mean differences for each sample size. ::: {.cell}\nsample_sizes &lt;- c(50, 200, 500, 1000)\n\npar(mfrow = c(2, 2))  # 2x2 grid of plots\n\nfor (n in sample_sizes) {\n  diffs &lt;- replicate(1000, {\n    m_treat &lt;- mean(rbinom(n, 1, 0.022))\n    m_ctrl &lt;- mean(rbinom(n, 1, 0.018))\n    m_treat - m_ctrl\n  })\n  hist(diffs,\n       main = paste(\"Sample size =\", n),\n       xlab = \"Mean Differences\",\n       col = \"lightblue\",\n       border = \"white\")\n}\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))  # reset layout\n:::\n\n\nInterpretation\nThese four histograms provide a striking visual of the Central Limit Theorem in action:\n\nSmall samples (n = 50) produce wider, bumpier distributions — lots of variation and a high chance of sampling noise.\nAs sample size increases (n = 200, 500, 1000), the distributions become smoother and more bell-shaped, and they center more tightly around the true difference (0.004).\n\nIn all cases, the peak of the histogram tends to cluster near the actual expected difference between treatment and control. This shows how even when dealing with binary outcomes (like whether someone donates), sample averages will behave predictably with enough data."
  },
  {
    "objectID": "blog/ab_testing/hw1_questions.html#conclusion",
    "href": "blog/ab_testing/hw1_questions.html#conclusion",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Conclusion",
    "text": "Conclusion\nThis replication of Karlan and List’s (2007) field experiment confirms several of their key findings: simply offering a matching donation significantly increases the likelihood that someone donates, while the specific size of the match (1:1, 2:1, 3:1) has little additional impact. Moreover, while more people give when a match is present, the size of their donation does not appear to increase, suggesting the match offer primarily affects participation, not generosity. Through simulation, we also demonstrated fundamental statistical principles that help explain why their findings hold in large samples. Altogether, this analysis reinforces the power of simple behavioral nudges in fundraising, and highlights the importance of both thoughtful experimental design and rigorous statistical interpretation in social science research."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Minh Vo",
    "section": "",
    "text": "I’m a Master of Science in Business Analytics candidate at UC San Diego’s Rady School of Management, with a background in Business Economics and a minor in Cognitive Science. My experience spans teaching, procurement analysis, and academic research, most recently assisting faculty across multiple upper-division management courses and leading a UCSD-funded research project on historical land use using QGIS and STATA. With strong technical skills in R, Python, SQL, and STATA, I’m passionate about turning data into insights that drive strategic decision-making."
  }
]