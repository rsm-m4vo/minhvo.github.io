---
title: "A Replication of Karlan and List (2007)"
author: "Minh Vo"
date: 2025-04-20
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes
format: html
---


## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).

In this experiment, Dean Karlan and John List wanted to understand what makes people more likely to donate to a cause, specifically, whether offering to match donations actually works. They mailed out 50,000 fundraising letters to past donors of a nonprofit, randomly assigning each recipient to one of a few different versions. Some people got a standard letter, while others were told their donation would be matched — either dollar-for-dollar (1:1), doubled (2:1), or tripled (3:1). A few versions also included different thresholds for how much the matching donor would contribute in total. By comparing how people responded across these groups, the researchers could see not just whether matching worked, but whether the size or structure of the match made a difference. As it would turn out, even just offering a match, any match, made people more likely to give.

This project seeks to replicate their results.


## Data

### Description

We begin by loading the dataset using the haven package, which allows us to read Stata .dta files into R. The dataset contains 50,083 observations, each representing an individual who received a fundraising letter. It includes information on treatment assignment, match ratios, suggested donation amounts, previous giving behavior, and demographic characteristics.

```{r}
library(haven)
library(dplyr)
library(ggplot2)

# Load data
df <- read_dta("../../data/karlan_list_2007.dta")

df %>%
  select(treatment, gave, amount, mrm2, female, ask, hpa) %>%
  summary()

```

### Variable Definitions

| Variable             | Description                                                         |
|----------------------|---------------------------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |


### Balance Test 

As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.

To assess the success of the randomization, we compare the treatment and control groups on a pre-treatment variable: mrm2, which represents the number of months since the last donation. If the randomization was effective, we would expect no significant differences between the two groups on this variable.

#### T-test for balance
```{r}
t.test(mrm2 ~ treatment, data = df)
```

The two-sample t-test yields a p-value of 0.9049, suggesting that there is no statistically significant difference between the treatment and control groups in terms of their recency of last donation.

#### Regression for balance
```{r}
summary(lm(mrm2 ~ treatment, data = df))
```

The linear regression confirms this result. The estimated coefficient on treatment is very small (≈ 0.014) and not statistically significant (p = 0.905), indicating that group assignment does not explain any meaningful variation in donation recency.

These results align with the balance checks shown in Table 1 of the original paper, which are included to assure readers that the random assignment created comparable groups. This gives us confidence that any differences observed in donation behavior later on can be attributed to the treatment itself.

## Experimental Results

### Charitable Contribution Made

First, I analyze whether matched donations lead to an increased response rate of making a donation. 

```{r}
# Proportion barplot
prop_data <- df %>%
  group_by(treatment) %>%
  summarise(rate = mean(gave))

ggplot(prop_data, aes(x = factor(treatment), y = rate, fill = factor(treatment))) +
  geom_bar(stat = "identity") +
  labs(x = "Group (0 = Control, 1 = Treatment)", y = "Proportion Donated", fill = "Group") +
  ggtitle("Donation Rate by Treatment Group") +
  scale_fill_manual(values = c("#FF6F61", "#00BFC4")) +
  theme_minimal()
```
This visual shows that the donation rate was noticeably higher among those who received a matching offer.

#### T-test and Linear Regression

We now formally test the difference in donation rates using both a two-sample t-test and a simple linear regression.

```{r}
# T-test
t.test(gave ~ treatment, data = df)

# Linear regression
summary(lm(gave ~ treatment, data = df))
```

Both approaches yield consistent results. The t-test produces a statistically significant p-value (~0.0013), and the regression confirms that being in the treatment group increases the likelihood of donating by about 0.4 percentage points. While this may seem small, it’s meaningful given the very low baseline donation rate (~1.8% in the control group). These results replicate Table 2a Panel A in the original paper and demonstrate that even a modest match offer has a real behavioral effect.

#### Probit Regression
To further validate the result, we run a probit regression where the dependent variable is gave and the independent variable is treatment.

```{r}
summary(glm(gave ~ treatment, family = binomial(link = "probit"), data = df))
```

The probit model returns a positive and statistically significant coefficient on the treatment variable, indicating that the matching offer significantly increases the probability of donating. This aligns with Table 3, Column 1 of the original study.

### Differences between Match Rates

In this section, we explore whether the size of the matching ratio affects the likelihood of giving. Specifically, we test whether individuals were more likely to donate when offered a 2:1 or 3:1 match compared to a standard 1:1 match.

#### T-tests Between Match Ratios

We begin by running two pairwise t-tests:
- The first compares donation rates between those offered a 1:1 match and those offered a 2:1 match.
- The second compares 2:1 and 3:1 match groups.

```{r}
# 1:1 vs 2:1
t.test(df$gave[df$ratio2 == 1], df$gave[df$ratio == 1])

# 2:1 vs 3:1
t.test(df$gave[df$ratio3 == 1], df$gave[df$ratio2 == 1])
```

The p-values for both comparisons (0.33 and 0.96, respectively) suggest that differences in match ratios do not produce statistically significant changes in donation behavior. This supports the authors’ observation in the paper that while match presence boosts donations, increasing the match size offers diminishing returns.

#### Regression on Match Ratios

We also run a regression using indicator variables for 2:1 and 3:1 matches (with 1:1 match as the omitted baseline):

```{r}
summary(lm(gave ~ ratio2 + ratio3, data = df))
```

The regression shows that being offered a 2:1 match increases the likelihood of giving by ~0.36 percentage points compared to a 1:1 match, while a 3:1 match increases it by ~0.37 points. Both coefficients are statistically significant at the 5% level. However, the practical effect sizes are small, and the increase from 2:1 to 3:1 is negligible — suggesting diminishing marginal returns to match size.

```{r}
# Mean donation rates
mean_1to1 <- mean(df$gave[df$ratio == 1])
mean_2to1 <- mean(df$gave[df$ratio2 == 1])
mean_3to1 <- mean(df$gave[df$ratio3 == 1])

# Differences
diff_2vs1 <- mean_2to1 - mean_1to1
diff_3vs2 <- mean_3to1 - mean_2to1
```

These calculations confirm the regression results. The response rate increases slightly from 1:1 to 2:1, and barely at all from 2:1 to 3:1. This aligns with the authors' interpretation on page 8, where they suggest that the presence of a match matters more than its size.

#### Interpretation
The evidence here suggests that once donors are presented with a match, increasing the match ratio (from 1:1 to 2:1 to 3:1) does not substantially change behavior. This has important implications for nonprofits: just offering a match may be sufficient, and investing in larger match ratios might not yield proportionally better outcomes.

#### Difference in Response Rates
Finally, we compare raw response rates directly:

### Size of Charitable Contribution

So far, we've focused on whether the matching offer increases the **likelihood** of donating. Now, we turn to the **size** of the donation. Does the presence of a match lead to larger contributions?

#### Average Donation Amount (All Participants)

First, we run a regression on the full dataset, comparing average donation amounts between the treatment and control groups.
```{r}
summary(lm(amount ~ treatment, data = df))
```

The treatment group gives about $0.15 more on average than the control group, but the difference is not statistically significant at the conventional 5% level (p = 0.063). This weak evidence suggests that while more people may give when matched, their contribution amounts do not increase meaningfully.

#### Average Donation Among Donors Only
Next, we restrict our analysis to only those who donated (gave == 1) to assess whether matched donors give more conditional on giving.
```{r}
df_givers <- df %>% filter(gave == 1)
summary(lm(amount ~ treatment, data = df_givers))
```

Among donors, the treatment effect disappears entirely. In fact, treated donors gave $1.67 less on average than the control group — though again, this result is not statistically significant (p = 0.56). This suggests that while match offers may encourage more people to give, they don’t necessarily give more money once they do.

#### Donation Amount Distributions
To visualize the donation behavior of those who gave, we plot histograms of donation amounts for the treatment and control groups. The red vertical line in each plot represents the group’s average donation.

```{r}
# Treatment group
ggplot(df_givers %>% filter(treatment == 1), aes(x = amount)) +
  geom_histogram(binwidth = 10, fill = "steelblue") +
  geom_vline(aes(xintercept = mean(amount)), color = "red", linetype = "dashed") +
  labs(title = "Donation Amounts (Treatment Group)", x = "Amount", y = "Count") +
  theme_minimal()

# Control group
ggplot(df_givers %>% filter(treatment == 0), aes(x = amount)) +
  geom_histogram(binwidth = 10, fill = "darkorange") +
  geom_vline(aes(xintercept = mean(amount)), color = "red", linetype = "dashed") +
  labs(title = "Donation Amounts (Control Group)", x = "Amount", y = "Count") +
  theme_minimal()
```

These plots show that the donation distributions are quite similar. Both are right-skewed (most people give small amounts), and the average donation is roughly the same across groups.

#### Interpretation
This analysis reinforces a key idea from the original study: matching offers are effective at increasing participation, but not necessarily donation size. While the psychological nudge of a match encourages people to give, it doesn’t seem to change how much they give once they've decided to contribute. Also, because these results come from an observational regression, and giving is influenced by many factors, the treatment coefficient should not be interpreted as causal without stronger identification assumptions.

## Simulation Experiment

To reinforce our understanding of the t-statistic and the foundations of hypothesis testing, we run a simulation to illustrate the **Law of Large Numbers**. The idea is to observe how the difference in sample means behaves as the number of simulations grows.

Suppose we know the following “true” probabilities of donating:
- Control group (no match): 1.8% (`p = 0.018`)
- Treatment group (match offer): 2.2% (`p = 0.022`)

We'll simulate thousands of draws from each group and track how the average difference evolves.

### Law of Large Numbers

The Law of Large Numbers (LLN) tells us that as the number of observations increases, the sample average will converge to the true population mean. To visualize this, we simulate:
- 100,000 individuals from the control distribution
- 10,000 individuals from the treatment distribution (drawn with replacement from the control group)
- A vector of 10,000 differences in donation outcomes
- The cumulative average of these differences

```{r}
set.seed(123)
ctrl <- rbinom(100000, 1, 0.018)
treat <- rbinom(10000, 1, 0.022)
diffs <- treat - sample(ctrl, 10000)
cum_avg <- cumsum(diffs)/seq_along(diffs)

plot(cum_avg, type = "l", col = "blue", ylab = "Cumulative Avg Diff",
     main = "LLN: Cumulative Difference", xlab = "Simulations")
abline(h = 0.004, col = "red", lty = 2)
```

The red dashed line represents the true difference in donation probabilities: 0.022 - 0.018 = 0.004. As the number of simulations increases, the cumulative average converges toward this value — beautifully demonstrating the Law of Large Numbers in action.

#### Interpretation

This plot helps explain why, in large datasets, sample averages become reliable estimates of population parameters. It also reminds us that random variation in small samples can be misleading, but that variation smooths out as more data is collected — a core principle behind statistical inference.

### Central Limit Theorem

To complement the Law of Large Numbers, we now illustrate the **Central Limit Theorem (CLT)** using simulation. While LLN tells us the average converges to the truth, the CLT tells us **what the distribution of those averages looks like** — specifically, that they tend to follow a normal (bell-shaped) distribution as the sample size increases.

#### Simulation Setup

We simulate differences in donation rates between treatment and control groups using four different sample sizes - 50, 200, 500, and 1000. For each size:
- We draw `n` Bernoulli observations from both the treatment (`p = 0.022`) and control (`p = 0.018`) distributions.
- We calculate the difference in sample means.
- We repeat this 1,000 times to build a distribution of mean differences.
```{r}
sample_sizes <- c(50, 200, 500, 1000)

par(mfrow = c(2, 2))  # 2x2 grid of plots

for (n in sample_sizes) {
  diffs <- replicate(1000, {
    m_treat <- mean(rbinom(n, 1, 0.022))
    m_ctrl <- mean(rbinom(n, 1, 0.018))
    m_treat - m_ctrl
  })
  hist(diffs,
       main = paste("Sample size =", n),
       xlab = "Mean Differences",
       col = "lightblue",
       border = "white")
}

par(mfrow = c(1, 1))  # reset layout
```

#### Interpretation

These four histograms provide a striking visual of the Central Limit Theorem in action:

- Small samples (n = 50) produce wider, bumpier distributions — lots of variation and a high chance of sampling noise.

- As sample size increases (n = 200, 500, 1000), the distributions become smoother and more bell-shaped, and they center more tightly around the true difference (0.004).

In all cases, the peak of the histogram tends to cluster near the actual expected difference between treatment and control. This shows how even when dealing with binary outcomes (like whether someone donates), sample averages will behave predictably with enough data.

## Conclusion
This replication of Karlan and List's (2007) field experiment confirms several of their key findings: simply offering a matching donation significantly increases the likelihood that someone donates, while the specific size of the match (1:1, 2:1, 3:1) has little additional impact. Moreover, while more people give when a match is present, the size of their donation does not appear to increase, suggesting the match offer primarily affects participation, not generosity. Through simulation, we also demonstrated fundamental statistical principles that help explain why their findings hold in large samples. Altogether, this analysis reinforces the power of simple behavioral nudges in fundraising, and highlights the importance of both thoughtful experimental design and rigorous statistical interpretation in social science research.